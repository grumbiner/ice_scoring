Phase 1 testing -- simple capability tests, hindcast mode

Inputs: 
  CFSv2 ocean and atmospheric fields as needed by ice model

Outputs: daily and daily average to 16 days
  sea ice concentration
  thickness
  velocity 

Verification sources:
  Concentration -- NCEP 1/12th degree analysis
  Thickness     -- ? 
  Velocity      -- IABP
  Edge          -- ?

Model grid spacing: 
  dx <= 50 km, >= 10 km

Number of runs:
  details tbd, but at least from the 1st and 15th of each month of 2015
  the tbd: increase run numbers if needed to achieve performance scores 
      which can reliably distinguish between model and null forecasters.

Domain:
  ... ? 40 N to pole, and 50 S to 80 S
  
Performance metrics (each hemisphere as possible):
  Report the execution requirement (cores, seconds)
  Concentration -- 2x2 categorical, PoD, FaR, %correct, False confidence rate
                -- bias, rms, 
                -- Murphy skill score on rms, 
                -- -- vs. null forecasters of persistence, climatology, analogue
  Velocity -- error radius (... per Grumbine 2013)
           -- -- vs. null forecaster of operational sea ice drift model run w. same winds
  Edge     -- Dhukovsky et al.?



Phase 2 tests -- simple capabilities in forecast mode
as above, except:
Inputs: 
  GFS quarter degree atmosphere forecast to 16 days (NCEI archive)
  CFSv2 ocean
Model resolution:
  dx <= 25 km, >= 1 km


Phase 3 testing -- coupling the system
... ice + hycom (mom?)
... ice + atmosphere (feed cfsv2 ocean?)


